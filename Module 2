Модуль 2.
Задание 3.

Так как на HQ-RTR нет утилиты chrony и возможность выбора стратума, NTP-сервером будет выступать ISP

Конфигурация NTP-сервера (ISP)
Скачиваем пакет chrony:

apt-get install -y chrony

Приводим начало файла vim /etc/chrony.conf к следующему виду:

# Use public servers from the pool.ntp.org project.
# Please consider joining the pool (https://www.pool.ntp.org/join.html
#pool pool.ntp.org iburst

server 127.0.0.1 iburst prefer
hwtimestamp *
local stratum 5
allow 0/0
server 127.0.0.1 - указываем сервером синхронизации самого себя

iburst - принудительно отправляет пакеты для точности синхронизации

prefer - отдает приоритет этому серверу

hwtimestamp * - указывает сетевой интерфейс как собственный источник времени и синхронизирует клиентов с ним

local stratum 5 - указание иерархического уровня

allow 0/0 - разрешает подключение с любого IP-адреса


Запускаем и добавляем в автозагрузку утилиту chronyd:

systemctl enable --now chronyd

Проверка конфигурации NTP-сервера
Получаем вывод источников времени с помощью команды:

chronyc sources
Вывод:

MS Name/IP address        Stratum  Poll  Reach  LastRx  Last  sample
=============================================================================
^/ localhost.localdomain  0        8     377    -       +0ns[  +0ns] +/-  0ns

Получаем вывод уровня стратума с помощью связки команд:

chronyc tracking | grep Stratum
Вывод:

Stratum: 5

Конфигурация NTP-клиента EcoRouter
Указываем IP-адрес NTP-сервера:

ntp server 172.16.4.1

Указываем часовой пояс:

ntp timezone utc+5

Проверка конфигурации NTP-клиента EcoRouter
Проверяем командой:

show ntp status
Вывод:

Status Description
*      best
+      sync
-      failed
?      unknown

----------------------------------------------------------------------------------------------------
Status  |  VR name  |  Server  |  Stratum  |  Delay  |  Version  |  Offset  |  Last  |  Source IP
----------------------------------------------------------------------------------------------------
       *|    default|172.16.4.1|          5|   0.0391|          4|    0.0036|    3:26|        

Конфигурация NTP-клиента Alt Linux
Скачиваем пакет chrony:

apt-get install chrony

Приводим начало файла /etc/chrony.conf к следующему виду:

#pool pool.ntp.org iburst
server 172.16.4.1 iburst prefer
iburst - принудительно отправляет пакеты для точности синхронизации

prefer - отдает приоритет этому серверу


Запускаем утилиту chrony и добавляем ее в автозагрузку:

systemctl enable --now chronyd

Проверка конфигурации NTP-клиента Alt Linux
Проверка NTP-клиента на Alt Linux аналогична проверке NTP-сервера на Alt Linux

Задание 4.

Конфигурация SSH Alt Linux
Затронутые строки в конфигурационном файле SSH /etc/openssh/sshd_config должны выглядеть следующим образом:

Port 2024
MaxAuthTries 2
PubkeyAuthentication yes
PasswordAuthentication yes
Banner /etc/openssh/bannermotd
AllowUsers  sshuser
Первоначальная настройка SSH производилась в задании Настройка безопасного удаленного доступа на серверах HQ-SRV и BR-SRV из Модуля 1


Конфигурация Ansible
Устанавливаем необходимые пакеты:

apt-get install -y ansible sshpass

Редактируем указанные строки в конфигурационном файле /etc/ansible/ansible.cfg:

inventory = ./inventory.yml
host_key_checking = False
inventory = ./inventory.yml - путь до инвентарного файла

host_key_checking = False - отключение проверки ключа хоста


Далее заполняем инвентарный файл /etc/ansible/inventory.yml:

all:
  children:
    Networking:
      hosts:
        hq-rtr:
        br-rtr:
    Servers:
      hosts:
        hq-srv:
          ansible_host: 192.168.100.62
          ansible_port: 2024
    Clients:
      hosts:
        hq-cli:
          ansible_host: 192.168.200.14
          ansible_port: 2024

Создаем файлы с переменными для всех категорий и для категории Networking:

cd /etc/ansible
mkdir group_vars
touch group_vars/{all.yml,Networking.yml}

Редактируем их:

ansible_ssh_user: sshuser
ansible_ssh_pass: P@ssw0rd
ansible_python_interpreter: /usr/bin/python3
all.yml

ansible_connection: network_cli
ansible_network_os: ios
Networking.yml


Выполняем команду для ping`а всех машин:

ansible -m ping all
-m (--module-name) - параметр для указания модуля

ping - модуль

all - выполнить модуль для всех виртуальных машин, указанных в инвентарном файле

Задание 6.

Конфигурация BR-RTR:

Проброс портов с 80 на 8080 для работы сервиса wiki:

ip nat source static tcp 192.168.200.1 80 192.168.200.30 8080

Проброс портов с 2024 на 2024:

ip nat source static tcp 192.168.200.1 2024 192.168.200.30 2024

Конфигурация HQ-RTR:
Проброс портов с 2024 на 2024:

ip nat source static tcp 192.168.100.1 2024 192.168.100.62 2024
